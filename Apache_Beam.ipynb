{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMAulsdxdmvvPmR/wO/zMjX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/louisecastrof/Projects_and_Studies/blob/main/Apache_Beam.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Definições Apache Beam\n"
      ],
      "metadata": {
        "id": "Iokf_sSn47_P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Apache Beam\n",
        "É um modelo unificado e portátil (exemplo: construir pipelines para batch e streaming com o mesmo código basicamente) </br>\n",
        "Utiliza SDK para se comunicar com as linguagens (Python, Java, Go, etc) </br>\n",
        "Conversa com function API se comunica entre o runner e a engine e transcreve os componentes de execução necessários (PubSub, BigQuery, Kafka, GCS) </br>\n",
        "\n",
        "\n",
        "## Pipeline\n",
        "Pcollection - (similar ao RDD do spark) Coleção de dados ingeridos ou criados após uma transformação (leu ou escreveu na fonte: cria PCollection). São imutáveis. </br>\n",
        "Para gerá-las usamos o PTransform, libs específicas de uma readtransform. São comandos que ajudam a transformar, deduplicar, contar dentro da pipeline. </br>\n",
        "ParDo = \"Parallel do\": dá pra criar funções independentes. Você cria variáveis ou funções personalizadas que podem ser reutilizadas posteriormente </br>\n",
        "\n",
        "## Data Fusion?\n",
        "Data fusion é baseado no Dataflow, então as funcionalidades se preservam por um custo menor no Dataflow e maior no Datafusion devido à sua interface. </br>\n",
        "O Dataflow criaa tabela se não existir, appenda dados, tem max file size, parâmetros adicionais do BQ, frequência para trigger, Schema específico, etc. Tudo que o Data Fusion tiver, só que com menor custo.</br>"
      ],
      "metadata": {
        "id": "esM5KZGKWcAY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instalação Apache Beam"
      ],
      "metadata": {
        "id": "lvYX1OzS6Wup"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalando as libs - [interactive] para notebooks como o colab, se for para local apenas apache-beam\n",
        "!pip install apache-beam[interactive]\n",
        "import apache_beam as beam"
      ],
      "metadata": {
        "id": "WfY1suh5bmN8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pipeline"
      ],
      "metadata": {
        "id": "R-IgqnH93YbK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ReadFromText </br>\n",
        "\n",
        "O método ReadFromText do Apache Beam é uma função que permite ler dados de arquivos de texto e gerar um PCollection (coleção de dados) no pipeline do Apache Beam. Esse método é comumente usado na fase de entrada de dados do pipeline, em que dados são lidos a partir de uma fonte externa e transformados em um formato que possa ser processado pelo pipeline. </br>\n",
        "\n",
        "O ReadFromText suporta diferentes tipos de arquivos de texto, como CSV, JSON, arquivos de texto simples e muitos outros. Ele pode ser configurado para lidar com diferentes tipos de codificações de texto e delimitadores de campo, permitindo a leitura de diferentes formatos de arquivo de texto.</br>"
      ],
      "metadata": {
        "id": "Tm9g0K7M6mg1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir pipeline\n",
        "p1 = beam.Pipeline()\n",
        "\n",
        "# Atribuindo à pipeline voos pois poderá ser reutilizada\n",
        "voos = (\n",
        "p1\n",
        "  # ler arquivo, excluir o header\n",
        "  # pipes = um comando é usado com input do outro\n",
        "  | \"Importar Dados\" >> beam.io.ReadFromText(\"voos_sample.csv\", skip_header_lines = 1)\n",
        "  | \"Separar por Vírgulas\" >> beam.Map(lambda record: record.split(','))\n",
        "  | \"Mostrar Resultados\" >> beam.Map(print)\n",
        "    \n",
        ")\n",
        "\n",
        "# Executar\n",
        "p1.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "av04IOiib565",
        "outputId": "19badce5-aa3d-4069-c4e1-6d466a9aa3be"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        if (typeof window.interactive_beam_jquery == 'undefined') {\n",
              "          var jqueryScript = document.createElement('script');\n",
              "          jqueryScript.src = 'https://code.jquery.com/jquery-3.4.1.slim.min.js';\n",
              "          jqueryScript.type = 'text/javascript';\n",
              "          jqueryScript.onload = function() {\n",
              "            var datatableScript = document.createElement('script');\n",
              "            datatableScript.src = 'https://cdn.datatables.net/1.10.20/js/jquery.dataTables.min.js';\n",
              "            datatableScript.type = 'text/javascript';\n",
              "            datatableScript.onload = function() {\n",
              "              window.interactive_beam_jquery = jQuery.noConflict(true);\n",
              "              window.interactive_beam_jquery(document).ready(function($){\n",
              "                \n",
              "              });\n",
              "            }\n",
              "            document.head.appendChild(datatableScript);\n",
              "          };\n",
              "          document.head.appendChild(jqueryScript);\n",
              "        } else {\n",
              "          window.interactive_beam_jquery(document).ready(function($){\n",
              "            \n",
              "          });\n",
              "        }"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['2019-04-27', '19805', '2', 'LAX', 'JFK', '944', '14', '1736', '-29', '269', '2475', '2']\n",
            "['2019-04-27', '19805', '3', 'JFK', 'LAX', '1224', '-6', '1614', '39', '371', '2475', '3']\n",
            "['2019-04-27', '19805', '4', 'LAX', 'JFK', '1240', '25', '2028', '-27', '264', '2475', '4']\n",
            "['2019-04-27', '19805', '5', 'DFW', 'HNL', '1300', '-5', '1650', '15', '510', '3784', '5']\n",
            "['2019-04-27', '19805', '6', 'OGG', 'DFW', '1901', '126', '640', '95', '385', '3711', '6']\n",
            "['2019-04-27', '19805', '7', 'DFW', 'OGG', '1410', '125', '1743', '138', '497', '3711', '7']\n",
            "['2019-04-27', '19805', '8', 'HNL', 'DFW', '1659', '4', '458', '-22', '398', '3784', '8']\n",
            "['2019-04-27', '19805', '9', 'JFK', 'LAX', '648', '-7', '1029', '19', '365', '2475', '9']\n",
            "['2019-04-27', '19805', '10', 'LAX', 'JFK', '2156', '21', '556', '1', '265', '2475', '10']\n",
            "['2019-04-27', '19805', '12', 'LAX', 'JFK', '1113', '-2', '1910', '-40', '267', '2475', '11']\n",
            "['2019-04-27', '19805', '14', 'OGG', 'LAX', '2235', '5', '618', '-17', '270', '2486', '12']\n",
            "['2019-04-27', '19805', '15', 'BOS', 'ORD', '611', '-9', '756', '-19', '129', '867', '13']\n",
            "['2019-04-27', '19805', '16', 'SFO', 'JFK', '1312', '17', '2107', '-33', '268', '2586', '14']\n",
            "['2019-04-27', '19805', '17', 'ATL', 'MIA', '630', '-5', '813', '-17', '83', '594', '15']\n",
            "['2019-04-27', '19805', '18', 'SFO', 'JFK', '22', '112', '833', '88', '288', '2586', '16']\n",
            "['2019-04-27', '19805', '19', 'JFK', 'LAX', '1024', '-6', '1353', '18', '359', '2475', '17']\n",
            "['2019-04-27', '19805', '20', 'SFO', 'JFK', '1715', '135', '130', '120', '277', '2586', '18']\n",
            "['2019-04-27', '19805', '21', 'JFK', 'LAX', '1906', '-4', '2246', '16', '359', '2475', '19']\n",
            "['2019-04-27', '19805', '22', 'LAX', 'JFK', '1458', '-2', '2336', '11', '272', '2475', '20']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x7f8b85219af0>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create\n",
        "O método Create do Apache Beam é uma função que permite criar uma coleção de dados diretamente dentro do pipeline. Esse método é comumente usado na fase de entrada de dados do pipeline, em que dados são gerados internamente e transformados em um formato que possa ser processado pelo pipeline. </br>\n",
        "\n",
        "O Create permite criar uma PCollection (coleção de dados) a partir de uma lista de elementos em Python. Esses elementos podem ser de qualquer tipo, como inteiros, strings, tuplas, dicionários e objetos personalizados. O Create é útil quando se deseja criar uma coleção de dados estática que possa ser usada como entrada para as transformações do pipeline. </br>"
      ],
      "metadata": {
        "id": "3_YKwlMy3d1T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import apache_beam as beam\n",
        "\n",
        "p1 = beam.Pipeline()\n",
        "\n",
        "#Criando tuplas\n",
        "p1 | \"Tupla\" >> beam.Create( [ (\"Louise\", 28),(\"Taiga\", 8),(\"Luke\", 8) ] ) | \"print Tupla\" >> beam.Map(print)\n",
        "\n",
        "p1.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24LBiNqrdnw0",
        "outputId": "feeb1520-38dd-4e5b-e4e9-09b8e59d4741"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Louise', 28)\n",
            "('Taiga', 8)\n",
            "('Luke', 8)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x7f8b84608f40>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Redefinindo o pipeline para que os resultados não se misturem\n",
        "p1 = beam.Pipeline()\n",
        "\n",
        "# Criando listas\n",
        "p1 | \"Lista\" >> beam.Create([\"Green Day\",\"Radiohead\",\"Queens of the Stone Age\",\"Rammstein\",\"Carne Doce\"]) | \"print Lista\" >> beam.Map(print)\n",
        "\n",
        "p1.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVDvF1Fi3mw6",
        "outputId": "c7be0fdc-a256-4aeb-8768-6bd27eef3de8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Green Day\n",
            "Radiohead\n",
            "Queens of the Stone Age\n",
            "Rammstein\n",
            "Carne Doce\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x7f8b845ce760>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ReadFromText e WriteToText\n",
        "O ReadFromText e o WriteToText são dois métodos do Apache Beam que permitem ler e escrever dados em arquivos de texto, respectivamente. </br>\n",
        "\n",
        "O método ReadFromText é usado para ler dados de arquivos de texto, como CSV, JSON, arquivos de texto simples e muitos outros. Ele pode ser configurado para lidar com diferentes tipos de codificações de texto e delimitadores de campo, permitindo a leitura de diferentes formatos de arquivo de texto. O ReadFromText retorna uma coleção de dados (PCollection) com as linhas do arquivo lido, que pode ser usado como entrada para as transformações do pipeline. </br>\n",
        "\n",
        "Já o método WriteToText é usado para escrever uma PCollection em um arquivo de texto. Ele permite que você defina a localização do arquivo e outras opções, como a codificação de caracteres e o caractere de separação entre as linhas. Cada elemento da PCollection é escrito como uma linha separada no arquivo de texto. O WriteToText retorna um objeto vazio (PDone) que pode ser usado para controlar o fluxo do pipeline. </br>"
      ],
      "metadata": {
        "id": "y8J4WAcH4p8_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "p1 = beam.Pipeline()\n",
        "\n",
        "voos = (\n",
        "p1\n",
        "#importando dados do CSV\n",
        "  | \"Importar Dados\" >> beam.io.ReadFromText(\"voos_sample.csv\", skip_header_lines = 1)\n",
        "  | \"Separar por Vírgulas\" >> beam.Map(lambda record: record.split(','))\n",
        "  | \"Mostrar Resultados\" >> beam.Map(print)\n",
        "  # adicionar linha de gravar dados - exportando para arquivo txt\n",
        "  | \"Gravar Resultado\" >> beam.io.WriteToText(\"voos.txt\")\n",
        ")\n",
        "\n",
        "p1.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wab_pkg3fls5",
        "outputId": "cf91fc29-37aa-4977-85b3-d71e25db7bfc"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['2019-04-27', '19805', '2', 'LAX', 'JFK', '944', '14', '1736', '-29', '269', '2475', '2']\n",
            "['2019-04-27', '19805', '3', 'JFK', 'LAX', '1224', '-6', '1614', '39', '371', '2475', '3']\n",
            "['2019-04-27', '19805', '4', 'LAX', 'JFK', '1240', '25', '2028', '-27', '264', '2475', '4']\n",
            "['2019-04-27', '19805', '5', 'DFW', 'HNL', '1300', '-5', '1650', '15', '510', '3784', '5']\n",
            "['2019-04-27', '19805', '6', 'OGG', 'DFW', '1901', '126', '640', '95', '385', '3711', '6']\n",
            "['2019-04-27', '19805', '7', 'DFW', 'OGG', '1410', '125', '1743', '138', '497', '3711', '7']\n",
            "['2019-04-27', '19805', '8', 'HNL', 'DFW', '1659', '4', '458', '-22', '398', '3784', '8']\n",
            "['2019-04-27', '19805', '9', 'JFK', 'LAX', '648', '-7', '1029', '19', '365', '2475', '9']\n",
            "['2019-04-27', '19805', '10', 'LAX', 'JFK', '2156', '21', '556', '1', '265', '2475', '10']\n",
            "['2019-04-27', '19805', '12', 'LAX', 'JFK', '1113', '-2', '1910', '-40', '267', '2475', '11']\n",
            "['2019-04-27', '19805', '14', 'OGG', 'LAX', '2235', '5', '618', '-17', '270', '2486', '12']\n",
            "['2019-04-27', '19805', '15', 'BOS', 'ORD', '611', '-9', '756', '-19', '129', '867', '13']\n",
            "['2019-04-27', '19805', '16', 'SFO', 'JFK', '1312', '17', '2107', '-33', '268', '2586', '14']\n",
            "['2019-04-27', '19805', '17', 'ATL', 'MIA', '630', '-5', '813', '-17', '83', '594', '15']\n",
            "['2019-04-27', '19805', '18', 'SFO', 'JFK', '22', '112', '833', '88', '288', '2586', '16']\n",
            "['2019-04-27', '19805', '19', 'JFK', 'LAX', '1024', '-6', '1353', '18', '359', '2475', '17']\n",
            "['2019-04-27', '19805', '20', 'SFO', 'JFK', '1715', '135', '130', '120', '277', '2586', '18']\n",
            "['2019-04-27', '19805', '21', 'JFK', 'LAX', '1906', '-4', '2246', '16', '359', '2475', '19']\n",
            "['2019-04-27', '19805', '22', 'LAX', 'JFK', '1458', '-2', '2336', '11', '272', '2475', '20']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x7f8b7f8a98e0>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Map\n",
        "O método Map do Apache Beam é uma função que permite aplicar uma transformação em cada elemento de uma PCollection (coleção de dados), gerando exatamente um elemento de saída para cada elemento de entrada. </br>\n",
        "\n",
        "O Map é útil quando se deseja transformar cada elemento de uma PCollection, como modificar ou extrair informações específicas de um elemento. Alguns exemplos de aplicação do Map são: extrair um campo de um registro, aplicar uma função matemática a cada elemento ou converter o tipo de dados de uma PCollection. </br>"
      ],
      "metadata": {
        "id": "NjP3x5iBh8TW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import apache_beam as beam\n",
        "\n",
        "p1 = beam.Pipeline()\n",
        "\n",
        "voos = (\n",
        "p1\n",
        "  | \"Importar Dados\" >> beam.io.ReadFromText(\"voos_sample.csv\", skip_header_lines = 1)\n",
        "  | \"Separar por Vírgulas\" >> beam.Map(lambda record: record.split(','))\n",
        "  | \"Mostrar Resultados\" >> beam.Map(print)\n",
        ")\n",
        "\n",
        "p1.run()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IlUWZAjB80jC",
        "outputId": "9a27a9fd-c9cf-49e2-9dcd-5ca6cd5d78da"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['2019-04-27', '19805', '2', 'LAX', 'JFK', '944', '14', '1736', '-29', '269', '2475', '2']\n",
            "['2019-04-27', '19805', '3', 'JFK', 'LAX', '1224', '-6', '1614', '39', '371', '2475', '3']\n",
            "['2019-04-27', '19805', '4', 'LAX', 'JFK', '1240', '25', '2028', '-27', '264', '2475', '4']\n",
            "['2019-04-27', '19805', '5', 'DFW', 'HNL', '1300', '-5', '1650', '15', '510', '3784', '5']\n",
            "['2019-04-27', '19805', '6', 'OGG', 'DFW', '1901', '126', '640', '95', '385', '3711', '6']\n",
            "['2019-04-27', '19805', '7', 'DFW', 'OGG', '1410', '125', '1743', '138', '497', '3711', '7']\n",
            "['2019-04-27', '19805', '8', 'HNL', 'DFW', '1659', '4', '458', '-22', '398', '3784', '8']\n",
            "['2019-04-27', '19805', '9', 'JFK', 'LAX', '648', '-7', '1029', '19', '365', '2475', '9']\n",
            "['2019-04-27', '19805', '10', 'LAX', 'JFK', '2156', '21', '556', '1', '265', '2475', '10']\n",
            "['2019-04-27', '19805', '12', 'LAX', 'JFK', '1113', '-2', '1910', '-40', '267', '2475', '11']\n",
            "['2019-04-27', '19805', '14', 'OGG', 'LAX', '2235', '5', '618', '-17', '270', '2486', '12']\n",
            "['2019-04-27', '19805', '15', 'BOS', 'ORD', '611', '-9', '756', '-19', '129', '867', '13']\n",
            "['2019-04-27', '19805', '16', 'SFO', 'JFK', '1312', '17', '2107', '-33', '268', '2586', '14']\n",
            "['2019-04-27', '19805', '17', 'ATL', 'MIA', '630', '-5', '813', '-17', '83', '594', '15']\n",
            "['2019-04-27', '19805', '18', 'SFO', 'JFK', '22', '112', '833', '88', '288', '2586', '16']\n",
            "['2019-04-27', '19805', '19', 'JFK', 'LAX', '1024', '-6', '1353', '18', '359', '2475', '17']\n",
            "['2019-04-27', '19805', '20', 'SFO', 'JFK', '1715', '135', '130', '120', '277', '2586', '18']\n",
            "['2019-04-27', '19805', '21', 'JFK', 'LAX', '1906', '-4', '2246', '16', '359', '2475', '19']\n",
            "['2019-04-27', '19805', '22', 'LAX', 'JFK', '1458', '-2', '2336', '11', '272', '2475', '20']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x7f8bb4e6f9d0>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Flat Map\n",
        "O método FlatMap do Apache Beam é uma função que permite aplicar uma transformação em cada elemento de uma PCollection (coleção de dados), gerando zero ou mais elementos de saída para cada elemento de entrada. A principal diferença entre o Map e o FlatMap é que o FlatMap permite gerar uma saída de zero a muitos elementos, enquanto o Map gera uma saída de exatamente um elemento para cada entrada. </br>\n",
        "\n",
        "O FlatMap é útil quando se deseja que uma única entrada gere várias saídas ou quando se deseja filtrar algumas entradas e gerar saídas a partir de outras. Alguns exemplos de aplicação do FlatMap são: quebrar uma string em palavras, filtrar elementos de uma lista ou gerar várias saídas a partir de uma entrada, como duplicar uma entrada. </br>"
      ],
      "metadata": {
        "id": "YseSkdc48MQE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import apache_beam as beam\n",
        "\n",
        "p1 = beam.Pipeline()\n",
        "\n",
        "Collection = (\n",
        "    p1\n",
        "    |beam.io.ReadFromText('poema.txt')\n",
        "    |beam.FlatMap(lambda record: record.split(' '))\n",
        "    # exportando resultado para txt\n",
        "    |beam.io.WriteToText('resultado.txt')\n",
        ")\n",
        "p1.run()\n",
        "\n",
        "# Resultado - em todos os espaços há uma quebra de linha"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_SEi141ihQD",
        "outputId": "ecac3c43-abb2-4572-9d24-3f122de4e876"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x7f8b845aa970>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Filter lamba\n",
        "\n",
        "A transformação Filter do Apache Beam permite filtrar elementos de uma PCollection (coleção de dados), gerando uma nova PCollection contendo apenas os elementos que satisfazem uma determinada condição. Quando combinada com uma função lambda, a transformação Filter pode ser usada para filtrar elementos com base em uma expressão booleana especificada pela função lambda.\n",
        "\n",
        "A função lambda é uma função anônima que pode ser definida em linha e passada como argumento para a transformação Filter. A função lambda é executada em cada elemento da PCollection, e deve retornar um valor booleano True ou False que indica se o elemento deve ser mantido ou descartado, respectivamente.\n"
      ],
      "metadata": {
        "id": "vOhi7NvAi0V-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import apache_beam as beam\n",
        "\n",
        "p1 = beam.Pipeline()\n",
        "\n",
        "voos = (\n",
        "p1\n",
        "  | \"Importar Dados\" >> beam.io.ReadFromText(\"voos_sample.csv\", skip_header_lines = 1)\n",
        "  | \"Separar por Vírgulas\" >> beam.Map(lambda record: record.split(','))\n",
        "  | \"Pegar voos de Los Angeles\" >> beam.Filter(lambda record: record[3] == \"LAX\")\n",
        "  | \"Mostrar Resultados\" >> beam.Map(print)\n",
        ")\n",
        "\n",
        "p1.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iICj5zuEirwk",
        "outputId": "58ffac6d-5ba8-434c-e7d2-1d3ab2846277"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['2019-04-27', '19805', '2', 'LAX', 'JFK', '944', '14', '1736', '-29', '269', '2475', '2']\n",
            "['2019-04-27', '19805', '4', 'LAX', 'JFK', '1240', '25', '2028', '-27', '264', '2475', '4']\n",
            "['2019-04-27', '19805', '10', 'LAX', 'JFK', '2156', '21', '556', '1', '265', '2475', '10']\n",
            "['2019-04-27', '19805', '12', 'LAX', 'JFK', '1113', '-2', '1910', '-40', '267', '2475', '11']\n",
            "['2019-04-27', '19805', '22', 'LAX', 'JFK', '1458', '-2', '2336', '11', '272', '2475', '20']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x7fd0da09d970>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Filter lista\n",
        "\n",
        "Quando combinado com uma lista, a transformação Filter pode ser usada para filtrar elementos que não pertencem à lista.\n",
        "\n",
        "Para usar a transformação Filter com uma lista, você pode definir uma função que verifica se o elemento está contido na lista ou não, e passar essa função como argumento para a transformação Filter. Essa função pode ser definida de várias maneiras, incluindo uma função definida pelo usuário ou usando uma função built-in do Python, como lambda."
      ],
      "metadata": {
        "id": "23JrotgJ9pe5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import apache_beam as beam\n",
        "\n",
        "palavras=['quatro','um']\n",
        "\n",
        "def encontrarPalavras( i ):\n",
        " if i in palavras:\n",
        "    return True\n",
        "\n",
        "p1 = beam.Pipeline()\n",
        "\n",
        "Collection = (\n",
        "    p1\n",
        "    |beam.io.ReadFromText('poema.txt')\n",
        "    |beam.FlatMap(lambda record: record.split(' '))\n",
        "    |beam.Filter(encontrarPalavras)\n",
        "    |beam.Map(print)\n",
        ")\n",
        "p1.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1-Rrw3FkVwB",
        "outputId": "677e838b-f314-4908-8151-c0d17d846588"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "quatro\n",
            "quatro\n",
            "um\n",
            "quatro\n",
            "quatro\n",
            "um\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x7f8bade3ffa0>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Flatten\n",
        "\n",
        "O Flatten é uma transformação do Apache Beam que combina várias PCollections (coleções de dados) do mesmo tipo em uma única PCollection. Ele recebe como entrada uma lista de PCollections e produz uma única PCollection que contém todos os elementos de todas as PCollections de entrada."
      ],
      "metadata": {
        "id": "iK7jb7R5yVB3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import apache_beam as beam\n",
        "\n",
        "p = beam.Pipeline()\n",
        "\n",
        "negros = ('Adão','Jesus','Mike')\n",
        "brancos = ('Tulio','Mary','Joca')\n",
        "indios = ('Vic','Marta','Tom')\n",
        "\n",
        "negros_pc = p | \"Criando Pcollection negros\" >> beam.Create(negros)\n",
        "brancos_pc = p | \"Criando Pcollection brancos\" >> beam.Create(brancos)\n",
        "indios_pc = p | \"Criando Pcollection indios\" >> beam.Create(indios)\n",
        "\n",
        "pessoas = ((negros_pc,brancos_pc,indios_pc) | beam.Flatten()) | beam.Map(print)\n",
        "p.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9ifh1nfyUSM",
        "outputId": "3638fc33-9f3a-4018-8024-2570eb4beffd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adão\n",
            "Jesus\n",
            "Mike\n",
            "Tulio\n",
            "Mary\n",
            "Joca\n",
            "Vic\n",
            "Marta\n",
            "Tom\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x7f8b848fe7c0>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Combine Per Key\n",
        "\n",
        "A transformação CombinePerKey do Apache Beam combina os valores de uma PCollection que compartilham a mesma chave, usando uma função de agregação fornecida pelo usuário. Essa transformação é comumente usada para agregar dados em pipelines de processamento de dados distribuídos.\n",
        "\n",
        "Para usar a transformação CombinePerKey, é necessário que a PCollection de entrada seja do tipo KV (key-value), onde cada elemento é uma tupla (chave, valor)."
      ],
      "metadata": {
        "id": "udy9bSWm1BSB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import apache_beam as beam\n",
        "\n",
        "p1 = beam.Pipeline()\n",
        "\n",
        "Tempo_Atrasos = (\n",
        "p1\n",
        "  | \"Importar Dados\" >> beam.io.ReadFromText(\"voos_sample.csv\")\n",
        "  | \"Separar por Vírgulas\" >> beam.Map(lambda record: record.split(','))\n",
        "  | \"Pegar voos de Los Angeles\" >> beam.Filter(lambda record: int(record[8]) > 0 )\n",
        "  | \"Criar par\" >> beam.Map(lambda record: (record[4],int(record[8])))\n",
        "  | \"Somar por key\" >> beam.CombinePerKey(sum)\n",
        "  | \"Mostrar Resultados\" >> beam.Map(print)\n",
        ")\n",
        "\n",
        "p1.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ey0Wr8ca1EPG",
        "outputId": "6f89bf0d-2f10-4935-ecc3-adccd695f713"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('LAX', 94)\n",
            "('HNL', 15)\n",
            "('DFW', 95)\n",
            "('OGG', 138)\n",
            "('JFK', 220)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x7f8b84986490>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Combiners.Count.PerKey()\n",
        "\n",
        "A transformação combiners.Count.PerKey() do Apache Beam conta o número de valores associados a cada chave em uma PCollection do tipo KV (key-value). Essa transformação é um exemplo de um transformador de combinação que combina os valores de entrada para cada chave usando a função de agregação Count.\n",
        "\n",
        "Por exemplo, suponha que você tenha uma PCollection com dados de vendas de produtos, onde cada venda é identificada por um código de produto, e você deseja contar o número de vendas para cada produto. Para isso, você pode usar a transformação combiners.Count.PerKey()"
      ],
      "metadata": {
        "id": "XQQa4DZ41Wca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import apache_beam as beam\n",
        "\n",
        "p1 = beam.Pipeline()\n",
        "\n",
        "Qtd_Atrasos = (\n",
        "    p1\n",
        "    | \"Importar Dados\" >> beam.io.ReadFromText(\"voos_sample.csv\", skip_header_lines = 1)\n",
        "    | \"Separar por Vírgulas\" >> beam.Map(lambda record: record.split(','))\n",
        "    | \"Pegar voos de Los Angeles\" >> beam.Filter(lambda record: int(record[8]) > 0 )\n",
        "    | \"Criar par\" >> beam.Map(lambda record: (record[4],int(record[8])))\n",
        "    | \"Contar por key\" >> beam.combiners.Count.PerKey()\n",
        "    | \"Mostrar Resultados\" >> beam.Map(print)\n",
        ")\n",
        "\n",
        "p1.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOmc6l7w1Iqi",
        "outputId": "c5a4d2be-9b72-47dc-fdfd-5cf340771fb4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('LAX', 4)\n",
            "('HNL', 1)\n",
            "('DFW', 1)\n",
            "('OGG', 1)\n",
            "('JFK', 4)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x7f8b84951a60>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CoGroupByKey\n",
        "\n",
        "A transformação CoGroupByKey do Apache Beam é usada para combinar múltiplas PCollections do tipo KV (key-value) com as mesmas chaves, agrupando todos os valores associados a cada chave em uma tupla.\n",
        "\n",
        "Por exemplo, suponha que você tenha duas PCollections com dados de vendas de produtos, uma contendo as quantidades vendidas de cada produto e outra contendo os preços unitários de cada produto. Você pode usar a transformação CoGroupByKey para combinar essas duas coleções com base no código do produto, criando uma tupla para cada código de produto que contém as quantidades vendidas e os preços unitários correspondentes.\n"
      ],
      "metadata": {
        "id": "-kULeOba1bqr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import apache_beam as beam\n",
        "\n",
        "p1 = beam.Pipeline()\n",
        "\n",
        "Tempo_Atrasos = (\n",
        "  p1\n",
        "  | \"Importar Dados Atraso\" >> beam.io.ReadFromText(\"voos_sample.csv\", skip_header_lines = 1)\n",
        "  | \"Separar por Vírgulas Atraso\" >> beam.Map(lambda record: record.split(','))\n",
        "  | \"Pegar voos com atraso\" >> beam.Filter(lambda record: int(record[8]) > 0 )\n",
        "  | \"Criar par atraso\" >> beam.Map(lambda record: (record[4],int(record[8])))\n",
        "  | \"Somar por key\" >> beam.CombinePerKey(sum)\n",
        "#  | \"Mostrar Resultados\" >> beam.Map(print)\n",
        ")\n",
        "\n",
        "Qtd_Atrasos = (\n",
        "  p1\n",
        "  | \"Importar Dados\" >> beam.io.ReadFromText(\"voos_sample.csv\", skip_header_lines = 1)\n",
        "  | \"Separar por Vírgulas\" >> beam.Map(lambda record: record.split(','))\n",
        "  | \"Pegar voos com atraso qtd\" >> beam.Filter(lambda record: int(record[8]) > 0 )\n",
        "  | \"Criar par qtd\" >> beam.Map(lambda record: (record[4],int(record[8])))\n",
        "  | \"Contar por key\" >> beam.combiners.Count.PerKey()\n",
        "#  | \"Mostrar Resultados QTD\" >> beam.Map(print)\n",
        ")\n",
        "\n",
        "tabela_atrasos = (\n",
        "    {'Qtd_Atrasos':Qtd_Atrasos,'Tempo_Atrasos':Tempo_Atrasos} \n",
        "    | \"Group By\" >> beam.CoGroupByKey()\n",
        "    | beam.Map(print)\n",
        ")\n",
        "\n",
        "p1.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0cGTqTOz1R1R",
        "outputId": "683a89c6-ac83-4a7d-f553-6311388e0065"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('LAX', {'Qtd_Atrasos': [4], 'Tempo_Atrasos': [92]})\n",
            "('HNL', {'Qtd_Atrasos': [1], 'Tempo_Atrasos': [15]})\n",
            "('DFW', {'Qtd_Atrasos': [1], 'Tempo_Atrasos': [95]})\n",
            "('OGG', {'Qtd_Atrasos': [1], 'Tempo_Atrasos': [138]})\n",
            "('JFK', {'Qtd_Atrasos': [4], 'Tempo_Atrasos': [220]})\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x7f8b845b6760>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ParDo – Funções Customizadas\n",
        "\n",
        "A transformação ParDo do Apache Beam é uma das transformações mais versáteis e amplamente utilizadas na plataforma. Ela permite a execução de funções customizadas em elementos de uma PCollection e a geração de novos elementos como saída.\n",
        "\n",
        "O nome \"ParDo\" é uma abreviação de \"parallel do\", o que indica que a transformação pode executar a função de forma paralela em várias instâncias do worker em um ambiente distribuído.\n",
        "\n",
        "Em um pipeline Beam típico, a transformação ParDo é frequentemente usada para transformar dados de entrada em um formato diferente ou para aplicar lógica de negócios personalizada."
      ],
      "metadata": {
        "id": "aN08G3Uz1nQB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import apache_beam as beam\n",
        "\n",
        "p1 = beam.Pipeline()\n",
        "\n",
        "class filtro(beam.DoFn):\n",
        "  def process(self,record):\n",
        "    if int(record[8]) > 0:\n",
        "      return [record]\n",
        "\n",
        "Tempo_Atrasos = (\n",
        "  p1\n",
        "  | \"Importar Dados Atraso\" >> beam.io.ReadFromText(r\"voos_sample.csv\", skip_header_lines = 1)\n",
        "  | \"Separar por Vírgulas Atraso\" >> beam.Map(lambda record: record.split(','))\n",
        "  | \"Pegar voos com atraso\" >> beam.ParDo(filtro())\n",
        "  | \"Criar par atraso\" >> beam.Map(lambda record: (record[4],int(record[8])))\n",
        "  | \"Somar por key\" >> beam.CombinePerKey(sum)\n",
        "#  | \"Mostrar Resultados\" >> beam.Map(print)\n",
        ")\n",
        "\n",
        "Qtd_Atrasos = (\n",
        "  p1\n",
        "  | \"Importar Dados\" >> beam.io.ReadFromText(r\"voos_sample.csv\", skip_header_lines = 1)\n",
        "  | \"Separar por Vírgulas Qtd\" >> beam.Map(lambda record: record.split(','))\n",
        "  | \"Pegar voos com Qtd\" >> beam.ParDo(filtro())\n",
        "  | \"Criar par Qtd\" >> beam.Map(lambda record: (record[4],int(record[8])))\n",
        "  | \"Contar por key\" >> beam.combiners.Count.PerKey()\n",
        "#  | \"Mostrar Resultados QTD\" >> beam.Map(print)\n",
        ")\n",
        "\n",
        "tabela_atrasos = (\n",
        "    {'Qtd_Atrasos':Qtd_Atrasos,'Tempo_Atrasos':Tempo_Atrasos} \n",
        "    | \"Group By\" >> beam.CoGroupByKey()\n",
        "    | beam.Map(print)\n",
        ")\n",
        "\n",
        "p1.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQqdwUJk1oR9",
        "outputId": "cd629a96-a108-44aa-ac02-531de9955c15"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('LAX', {'Qtd_Atrasos': [4], 'Tempo_Atrasos': [92]})\n",
            "('HNL', {'Qtd_Atrasos': [1], 'Tempo_Atrasos': [15]})\n",
            "('DFW', {'Qtd_Atrasos': [1], 'Tempo_Atrasos': [95]})\n",
            "('OGG', {'Qtd_Atrasos': [1], 'Tempo_Atrasos': [138]})\n",
            "('JFK', {'Qtd_Atrasos': [4], 'Tempo_Atrasos': [220]})\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x7f8b7f5fb760>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    }
  ]
}